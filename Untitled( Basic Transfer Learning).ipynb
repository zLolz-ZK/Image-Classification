{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%pwd\n",
    "%cd drive/My Drive/\n",
    "\n",
    "%cp Untitled.zip /content\n",
    "%cp model.091-1.00-1.50-0.79.h5 /content\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "filename='Untitled.zip'\n",
    "with ZipFile(filename,'r') as zip1:\n",
    "    zip1.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.getcwd()\n",
    "\n",
    "df_data = pd.read_csv(os.path.join(path,'train.csv'))\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will tell us how many images are associated with each Target(id)\n",
    "sum_df = df_data.groupby('target').count()\n",
    "\n",
    "sum_df#Total are 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['manipuri','bharatanatyam','odissi','kathakali',\n",
    "           'kathak', 'sattriya', 'kuchipudi', 'mohiniyattam',]\n",
    "\n",
    "base_dir = 'base_dir3'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "for cl in classes:\n",
    "    cl = os.path.join(base_dir, cl)\n",
    "    os.mkdir(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "width_list=[]\n",
    "height_list=[]\n",
    "IMG_SHAPE=299\n",
    "df=df_data.groupby('target')\n",
    "src_path=os.path.join(os.getcwd(),'train/')\n",
    "for cl in classes:\n",
    "    #img_path = os.path.join('/content/dataset/HackerEarthDLcomp',base_dir, cl)\n",
    "    img_path = os.path.join(os.getcwd(),base_dir, cl)\n",
    "   \n",
    "    c=0\n",
    "    \n",
    "    for i in range(len(df_data)):\n",
    "        img_type = df_data.loc[i,'target']\n",
    "        img_name = df_data.loc[i,'Image']\n",
    "\n",
    "        #x,y=Image.open(src_path+df_data.loc[i,'Image']).size\n",
    "        #width_list.append(x)\n",
    "        #height_list.append(y)\n",
    "        #print(src_path+img_name)\n",
    "        newsize=(IMG_SHAPE,IMG_SHAPE)\n",
    "        img=Image.open(src_path+img_name).resize(newsize)\n",
    "        img.save(os.path.join(src_path+img_name))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if cl == img_type:\n",
    "            c+=1\n",
    "            shutil.copy(src_path+img_name, os.path.join(img_path))\n",
    "    print(cl,c)\n",
    "    \n",
    "#print(min(width_list),min(height_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "df_data.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "df = df_data.groupby('target')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "'''\n",
    "import glob\n",
    "\n",
    "for cl in classes:\n",
    "    img_path = os.path.join(base_dir, cl)\n",
    "    images = glob.glob(img_path + '/*.jpg')\n",
    "    print(\"{}: {} Images\".format(cl, len(images)))\n",
    "    num_train = int(round(len(images)*1))\n",
    "    train, val = images[:num_train], images[num_train:]\n",
    "\n",
    "    for t in train:\n",
    "        if not os.path.exists(os.path.join(base_dir, 'train_dir', cl)):\n",
    "            os.makedirs(os.path.join(base_dir, 'train_dir', cl))\n",
    "        shutil.move(t, os.path.join(base_dir, 'train_dir', cl))\n",
    "\n",
    "    for v in val:\n",
    "        if not os.path.exists(os.path.join(base_dir, 'val_dir', cl)):\n",
    "            os.makedirs(os.path.join(base_dir, 'val_dir', cl))\n",
    "        shutil.move(v, os.path.join(base_dir, 'val_dir', cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "m = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_128/classification/4\")\n",
    "])\n",
    "m.build([None, 128, 128, 3])  # Batch input shape.\n",
    "'''\n",
    "from keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 32\n",
    "IMG_SHAPE = 299 #128\n",
    "''' rescale=1./255,\n",
    "                                     rotation_range=25,\n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     horizontal_flip=True,\n",
    "                                     width_shift_range=[-1.1,1.1],\n",
    "                                     height_shift_range=[-1.1,1.1],\n",
    "                                     brightness_range=(0.8,1.2),\n",
    "                                     #shear_range=25,\n",
    "                                     #zca_whitening=True,'''\n",
    "image_gen_train = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                     width_shift_range=[-1.1,1.1],\n",
    "                                     height_shift_range=[-1.1,1.1],\n",
    "                                     #brightness_range=(0.8,1.2),\n",
    "                                      shear_range=25,\n",
    "                                     )\n",
    "\n",
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                     shuffle=True,\n",
    "                                                     class_mode='sparse')\n",
    "\n",
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=val_dir,\n",
    "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "                                                 class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "URL1 = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_128/feature_vector/4'\n",
    "\n",
    "feature_extractor1 = hub.KerasLayer(URL1,\n",
    "                                   input_shape=(IMG_SHAPE, IMG_SHAPE,3))\n",
    "model0.trainable = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xce = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    pooling='max',\n",
    "    input_shape=(299,299,3),\n",
    "    )\n",
    "\n",
    "xce.trainable = False\n",
    "modelxce = tf.keras.Sequential([\n",
    "                               xce,\n",
    "                               #tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                               tf.keras.layers.Flatten(),\n",
    "                               tf.keras.layers.Dense(64,activation='relu'),\n",
    "\n",
    "                                tf.keras.layers.Dense(16,activation='relu'),\n",
    "                               tf.keras.layers.Dropout(0.1),\n",
    "                                tf.keras.layers.Dense(8,activation='relu'),\n",
    "                               tf.keras.layers.Dense(8,activation='softmax')                             \n",
    "])\n",
    "\n",
    "modelxce.compile(optimizer='adam',#tf.keras.optimizers.Adam() or 'SGD'\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['acc'])\n",
    "modelxce.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "history = modelxce.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(train_data_gen.n / float(batch_size))),\n",
    "    epochs=epochs,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxce.save('model_xce.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(os.getcwd(),'test')\n",
    "for i in range(len(df_test)):\n",
    "    #img_type = df_data.loc[i,'target']\n",
    "    img_name = df_test.loc[i,'Image']\n",
    "\n",
    "    img=Image.open(os.path.join(test_dir,img_name)).resize((299,299))\n",
    "    img = np.array(img)/255.0\n",
    "    img= preprocess_input(img)\n",
    "    res = modelxce.predict(img[np.newaxis, ...])\n",
    "    pred = np.argmax(res[0], axis =-1)\n",
    "\n",
    "    df_test.loc[i,'target'] = classes[pred]\n",
    "\n",
    "  #print(model1.predict(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('test5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
